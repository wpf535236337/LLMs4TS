# AI4TS

Awesome resources focus on the application of cutting-edge AI technologies for time-series analysis (**AI4TS**). They delve into advanced topics such as self-supervised learning (**SSL**), Graph Neural Networks for Time Series (**GNN4TS**), Large Language Models for Time Series (**LLM4TS**), **Diffusion** models, Mixture-of-Experts (**MoE**) architectures and **Mamba** models, Kolmogorov Arnold Networks (**KAN**),  Learn at Test Time (**TTT**) among others. These resources span various domains, including healthcare, finance, and traffic, offering a comprehensive view of the field. In addition, they feature top-notch tutorials, courses, and workshops from prestigious conferences, hosted by globally renowned scholars and research teams. Whether you're a professional, data scientist, or researcher, these tools and techniques can significantly enhance your time-series data analysis capabilities, providing a clear roadmap for your studies.

#### LLM4TS

* Forecasting
  * PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting [arxiv 20 Sep 2022](https://arxiv.org/abs/2210.08964) [PISA)](https://github.com/HaoUNSW/PISA)
  * Temporal Data Meets LLM -- Explainable Financial Time Series Forecasting [arxiv 19 Jun 2023](https://arxiv.org/abs/2306.11025)
  * Time-LLM: Time Series Forecasting by Reprogramming Large Language Models [arxiv 3 Oct 2023](https://arxiv.org/abs/2310.01728)
  * TimeGPT-1 [arxiv 2023 *5 Oct 2023*](https://arxiv.org/abs/2310.03589)
  * TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting [ arxiv 8 Oct 2023](https://arxiv.org/abs/2310.04948) 
  * Pushing the Limits of Pre-training for Time Series Forecasting in the CloudOps Domain [arxiv 2023 8 Oct 2023](https://arxiv.org/abs/2310.05063)
  * Large Language Models Are Zero-Shot Time Series Forecasters [ NeurIPS 2023 11 Oct 2023](https://arxiv.org/abs/2310.07820)  [llmtime](https://github.com/ngruver/llmtime)
  * Lag-Llama: Towards Foundation Models for Time Series Forecasting [arxiv 12 Oct 2023](https://arxiv.org/abs/2310.08278)  [Lag-Llama](https://github.com/kashif/pytorch-transformer-ts)
  * iTransformer: Inverted Transformers Are Effective for Time Series Forecasting [arxiv 13  Oct 2023 ]() [iTransformer]([GitHub - thuml/iTransformer: This is the official implementation for "iTransformer: Inverted Transformers Are Effective for Time Series Forecasting".](https://github.com/thuml/iTransformer))
  * Harnessing LLMs for Temporal Data - A Study on Explainable Financial Time Series Forecasting [2023.emnlp-industry](https://aclanthology.org/2023.emnlp-industry.69.pdf)
  * LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs [arxiv16 Aug 2023](https://arxiv.org/abs/2308.08469) 
  * UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting [15 Oct 2023](https://arxiv.org/abs/2310.09751)
  * AutoTimes: Autoregressive Time Series Forecasters via Large Language Models [4 Feb 2024](https://arxiv.org/abs/2402.02370)
  * Unified Training of Universal Time Series Forecasting Transformers [4 Feb 2024](https://arxiv.org/abs/2402.02592) [SalesforceAIResearch/uni2ts](https://github.com/SalesforceAIResearch/uni2ts)
  * LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting [25 Feb 2024](https://arxiv.org/abs/2402.16132v1) [LSTPrompt](https://github.com/AdityaLab/lstprompt)
  * Multi-Patch Prediction: Adapting LLMs for Time Series Representation Learning [7 Feb 2024](https://arxiv.org/abs/2402.04852)
  * Chronos: Learning the Language of Time Series [12 Mar 2024](https://arxiv.org/abs/2403.07815) [chronos](https://github.com/amazon-science/chronos-forecasting)
  * S^2 IP-LLM: Semantic Space Informed Prompt Learning with LLM for Time Series Forecasting [9 Mar 2024](https://arxiv.org/abs/2403.05798)
  * CALF: Aligning LLMs for Time Series Forecasting via Cross-modal Fine-Tuning [12 Mar 2024](https://arxiv.org/abs/2403.07300) [CALF](https://github.com/Hank0626/CALF)
  * TimeCMA: Towards LLM-Empowered Time Series Forecasting via Cross-Modality Alignment [3 Jun 2024](https://arxiv.org/abs/2406.01638)
  * TS-TCD: Triplet-Level Cross-Modal Distillation for Time-Series Forecasting Using Large Language Models [23 Sep 2024](https://arxiv.org/abs/2409.14978)
* Anomaly Detection
  * Large Language Model Guided Knowledge Distillation for Time Series Anomaly Detection [26 Jan 2024](https://arxiv.org/abs/2401.15123) [AnomalyLLM](https://github.com/fly-orange/AnomalyLLM/tree/main)
  * Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review [15 Feb 2024](https://arxiv.org/abs/2402.10350)
  * Large language models can be zero-shot anomaly detectors for time series?  [*23 May 2024*](https://arxiv.org/abs/2405.14755)
  * PeFAD: A Parameter-Efficient Federated Framework for Time Series Anomaly Detection [KDD2024](https://arxiv.org/abs/2406.02318)
* Imputation 
  * GATGPT: A Pre-trained Large Language Model with Graph Attention Network for Spatiotemporal Imputation [24 Nov 2023](https://arxiv.org/abs/2311.14332)
  * NuwaTS: a Foundation Model Mending Every Incomplete Time Series [24 May 2024](https://arxiv.org/abs/2405.15317) [Chengyui/NuwaTS](https://github.com/Chengyui/NuwaTS)
* Spatio-temporal prediction
  * Spatio-Temporal Graph Learning with Large Language Model [20 Sept 2023](https://openreview.net/forum?id=QUkcfqa6GX)
  * How Can Large Language Models Understand Spatial-Temporal Data? [25 Jan 2024](https://arxiv.org/abs/2401.14192)
  * UrbanGPT: Spatio-Temporal Large Language Models [25 Feb 2024](https://arxiv.org/abs/2403.00813)
  * TPLLM: A Traffic Prediction Framework Based on Pretrained Large Language Models [ 4 Mar 2024](https://arxiv.org/abs/2403.02221v1)
  * Spatial-Temporal Large Language Model for Traffic Prediction [18 Jan 2024](https://arxiv.org/abs/2401.10134) [ChenxiLiu-HNU/ST-LLM](https://github.com/ChenxiLiu-HNU/ST-LLM)
* One Fits all
  * One Fits All:Power General Time Series Analysis by Pretrained LM [arxiv 23 Feb 2023](https://arxiv.org/abs/2302.11939) [NeurIPS2023-One-Fits-All](https://github.com/DAMO-DI-ML/NeurIPS2023-One-Fits-All) [no-officail reproduction](https://github.com/liaoyuhua/GPT-TS)
  * TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series [arxiv16 Aug 2023](https://arxiv.org/abs/2308.08241#:~:text=TEST%3A%20Text%20Prototype%20Aligned%20Embedding%20to%20Activate%20LLM's%20Ability%20for%20Time%20Series,-Chenxi%20Sun%2C%20Yaliang&text=This%20work%20summarizes%20two%20strategies,LLM%20to%20handle%20TS%20data.) [TEST](https://github.com/SCXsunchenxi/TEST)
  * Timer: Transformers for Time Series Analysis at Scale [4 Feb 2024](https://arxiv.org/abs/2402.02368)
  * UniTS: Building a Unified Time Series Model  [29 Feb 2024](https://arxiv.org/abs/2403.00131v1) [UniTS](https://github.com/mims-harvard/UniTS)
  * MOMENT: A Family of Open Time-series Foundation Models [6 Feb 2024](https://arxiv.org/abs/2402.03885) [MOMENT](https://anonymous.4open.science/r/BETT-773F/README.md)
  * TSLANet: Rethinking Transformers for Time Series Representation Learning [ICML2024](https://arxiv.org/abs/2404.08472) [TSLANet](https://github.com/emadeldeen24/TSLANet)
  * RWKV-TS: Beyond Traditional Recurrent Neural Network for Time Series Tasks [17 Jan 2024](https://arxiv.org/abs/2401.09093) [RWKV-TS](https://github.com/howard-hou/RWKV-TS)
  * UniCL: A Universal Contrastive Learning Framework for Large Time Series Models [17 May 2024](https://arxiv.org/abs/2405.10597)
* Discussion
  * Language models still struggle to zero-shot reason about time series [17 Apr 2024](https://arxiv.org/abs/2404.11757)[TSandLanguage](https://github.com/behavioral-data/TSandLanguage)
  * Are Language Models Actually Useful for Time Series Forecasting? [22 Jun 2024](https://arxiv.org/pdf/2406.16964) [TS_Models](https://github.com/BennyTMT/TS_Models)
  * Towards Neural Scaling Laws for Time Series Foundation Models [16 Oct 2024](https://arxiv.org/abs/2410.12360)
  * Revisited Large Language Model for Time Series Analysis through Modality Alignment [16 Oct 2024](https://arxiv.org/abs/2410.12326)

#### Vision4TS

* VisionTS: Visual Masked Autoencoders Are Free-Lunch Zero-Shot Time Series Forecasters [30 Aug 2024](https://arxiv.org/abs/2408.17253) [Keytoyze/VisionTS](https://github.com/Keytoyze/VisionTS)
* CAFO: Feature-Centric Explanation on Time Series Classification [KDD2024](https://arxiv.org/abs/2406.01833)
* ViTime: A Visual Intelligence-Based Foundation Model for Time Series Forecasting [10 Jul 2024](https://arxiv.org/abs/2407.07311v2) [IkeYang/ViTime](https://github.com/IkeYang/ViTime)
* Hierarchical Context Representation and Self-Adaptive Thresholding for Multivariate Anomaly Detection [TKDE2024](https://ieeexplore.ieee.org/document/10417809)
* Training-Free Time-Series Anomaly Detection: Leveraging Image Foundation Models [27 Aug 2024](https://arxiv.org/abs/2408.14756)

#### Multimodal large models include TS

* Meta-Transformer: A Unified Framework for Multimodal Learning [20 Jul 2023](https://arxiv.org/abs/2307.10802) [Meta-Transformer](https://kxgong.github.io/meta_transformer/)
* UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio, Video,Point Cloud, Time-Series and Image Recognition [27 Nov 2023](https://arxiv.org/abs/2311.15599) [UniRepLKNet](https://invictus717.github.io/UniRepLKNet/)
* ViT-Lens-2: Gateway to Omni-modal Intelligence [27 Nov 2023](https://arxiv.org/abs/2311.16081) [ViT-Lens-2](https://github.com/TencentARC/ViT-Lens)

#### Patch && Tokenizers methods

* Patches Are All You Need? [*ICLR 24 Jan 2022*](https://arxiv.org/abs/2201.09792)  [convmixer](https://github.com/locuslab/convmixer)
* A Time Series is Worth 64 Words: Long-term Forecasting with Transformers [ICLR 2023 *27 Nov 2022*](https://arxiv.org/abs/2211.14730) [PatchTST](https://github.com/yuqinie98/PatchTST)
* PatchMixer: A Patch-Mixing Architecture for Long-Term Time Series Forecasting [arxiv  *1 Oct 2023*](https://arxiv.org/abs/2310.00655) [PatchMixer](https://github.com/Zeying-Gong/PatchMixer) [Chinese blog](https://mp.weixin.qq.com/s/gfAqL7bosdc0mxz8SziBbQ)
* Learning to Embed Time Series Patches Independently [NeurIPS Workshop on Self-Supervised Learning: Theory and Practice, 2023](https://arxiv.org/abs/2312.16427) [pits](https://github.com/seunghan96/pits)
* The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models [arxiv 12 Sep 2023](https://arxiv.org/abs/2309.06236)
* What Makes for Good Visual Tokenizers for Large Language Models? [20 May 2023](https://arxiv.org/abs/2305.12223) [GVT](https://github.com/TencentARC/GVT)
* SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models [ICLR2024](https://arxiv.org/abs/2308.16692) [SpeechTokenizer](https://0nutation.github.io/SpeechTokenizer.github.io/)
* Pathformer: Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting [ICLR2024](https://github.com/decisionintelligence/pathformer)
* From Similarity to Superiority: Channel Clustering for Time Series Forecasting [31 Mar 2024](https://arxiv.org/abs/2404.01340v1)
* TOTEM: TOkenized Time series EMbeddings for General Time Series Analysis [26 Feb 2024](https://arxiv.org/abs/2402.16412) [TOTEM](https://github.com/SaberaTalukder/TOTEM)
* Medformer: A Multi-Granularity Patching Transformer for Medical Time-Series Classification [arxiv24 May 2024](https://arxiv.org/abs/2405.19363) [DL4mHealth/Medformer](https://github.com/DL4mHealth/Medformer)
* 

#### GNN

* Graph-Aware Contrasting for Multivariate Time-Series Classification [AAAI2024](https://ojs.aaai.org/index.php/AAAI/article/view/29501) [TSGAC](https://github.com/Frank-Wang-oss/TS-GAC)
* GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable for Variable Missing [KDD2024](https://arxiv.org/abs/2405.11333)

#### MLPer

* TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting [KDD2023](https://arxiv.org/abs/2306.09364)[PatchTSMixer](https://github.com/IBM/tsfm/blob/main/notebooks/hfdemo/patch_tsmixer_getting_started.ipynb)
* A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis [VLDB2024](https://arxiv.org/abs/2310.11959) [zshhans/MSD-Mixer](https://github.com/zshhans/MSD-Mixer)
* Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced Zero/Few-Shot
  Forecasting of Multivariate Time Series [8 Jan 2024](https://arxiv.org/abs/2401.03955)
* U-Mixer: An Unet-Mixer Architecture with Stationarity Correction for Time Series Forecasting [AAAI2024](https://arxiv.org/abs/2401.02236) [U-Mixer](https://github.com/XiangMa-Shaun/U-Mixer)
* LightTS: Lightweight Time Series Classification with Adaptive
  Ensemble Distillation—Extended Version [SIGMOD 2023](https://arxiv.org/abs/2302.12721) 
* An Analysis of Linear Time Series Forecasting Models [ICML2024](https://arxiv.org/abs//2403.14587)
* SOFTS: Efficient Multivariate Time Series Forecasting with Series-Core Fusion [22 Apr 2024](https://arxiv.org/abs/2404.14197) [Secilia-Cxy/SOFTS](https://github.com/Secilia-Cxy/SOFTS)

#### Mixture-of-Experts (MoE)

* Mixture-of-Linear-Experts for Long-term Time Series Forecasting [11 Dec 2023](https://arxiv.org/abs/2312.06786)
* Prompt-based Domain Discrimination for Multi-source Time Series Domain Adaptation [19 Dec 2023](https://arxiv.org/abs/2312.12276)
* A Review of Sparse Expert Models in Deep Learning [4 Sep 2022](https://arxiv.org/abs/2209.01667)
* MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts [8 Jan 2024](https://arxiv.org/abs/2401.04081) [](https://github.com/llm-random/llm-random)
* ST-MoE: Spatio-Temporal Mixture of Experts for Multivariate Time Series Forecasting [2023ISKE](https://ieeexplore.ieee.org/abstract/document/10480934)
* [Tutorial for Mixture of Expert (MoE) Forecasting Model — Merlion 1.1.0 documentation (salesforce.com)](https://opensource.salesforce.com/Merlion/v1.1.0/examples/advanced/2_MoE_Forecasting_tutorial.html)
* Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts [24 Sep 2024](https://arxiv.org/abs/2409.16040) [Time-MoE](https://github.com/Time-MoE/Time-MoE)
* Moirai-MoE: Empowering Time Series Foundation Models with Sparse Mixture of Experts [14 Oct 2024](https://arxiv.org/abs/2410.10469v1) 

#### PEFT for TS

* One Fits All: Universal Time Series Analysis by Pretrained LM and Specially Designed Adaptors [24 Nov 2023](https://arxiv.org/abs/2311.14782) [GPT4TS_Adapter](https://github.com/PSacfc/GPT4TS_Adapter)
* Low-Rank Adaptation of Time Series Foundational Models for Out-of-Domain Modality Forecasting [16 May 2024](https://arxiv.org/abs/2405.10216)
* Personalized Adapter for Large Meteorology Model on Devices: Towards Weather Foundation Models [24 May 2024](https://arxiv.org/abs/2405.20348)
* DualTime: A Dual-Adapter Multimodal Language Model for Time Series Representation [7 Jun 2024](https://arxiv.org/abs/2410.10469v1)
* Channel-Aware Low-Rank Adaptation in Time Series Forecasting [CIKM2024](https://dl.acm.org/doi/abs/10.1145/3627673.3679884) [C-LoRA](https://github.com/tongnie/C-LoRA)
* 

#### Mamba 

* Is Mamba Effective for Time Series Forecasting? [17 Mar 2024](https://arxiv.org/abs/2403.11144) [wzhwzhwzh0921/S-D-Mamba](https://github.com/wzhwzhwzh0921/S-D-Mamba)
* TimeMachine: A Time Series is Worth 4 Mambas for Long-term Forecasting [14 Mar 2024](https://arxiv.org/abs/2403.09898) [Atik-Ahamed/TimeMachine](https://github.com/Atik-Ahamed/TimeMachine)
* STG-Mamba: Spatial-Temporal Graph Learning via Selective State Space Model [19 Mar 2024](https://arxiv.org/abs/2403.12418)
* SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series [22 Mar 2024](https://arxiv.org/abs/2403.15360) [badripatro/simba](https://github.com/badripatro/Simba)
* MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection [29 Mar 2024](https://arxiv.org/abs/2403.19888)
* Traj-LLM: A New Exploration for Empowering Trajectory Prediction with Pre-trained Large Language Models [8 May 2024](https://arxiv.org/abs/2405.04909)
* Time-SSM: Simplifying and Unifying State Space Models for Time Series Forecasting [25 May 2024](https://arxiv.org/abs/2405.16312)
* TSCMamba: Mamba Meets Multi-View Learning for Time Series Classification [6 Jun 2024](https://arxiv.org/abs/2406.04419)

#### KAN

* KAN: Kolmogorov-Arnold Networks [30 Apr 2024](https://arxiv.org/abs/2404.19756) [pykan](https://github.com/KindXiaoming/pykan)
* TKAN: Temporal Kolmogorov-Arnold Networks [arxiv12 May 2024](https://arxiv.org/abs/2405.07344) [TKAN](https://github.com/remigenet/TKAN)
* Kolmogorov-Arnold Networks (KANs) for Time Series Analysis [14 May 2024](https://arxiv.org/abs/2405.08790)
* Feature-Based Time Series Classification with Kolmogorov–Arnold Networks [Simple-KAN-4-Time-Series](https://github.com/MSD-IRIMAS/Simple-KAN-4-Time-Series)

#### TTT

* Learning to (Learn at Test Time): RNNs with Expressive Hidden States [5 Jul 2024 ](https://arxiv.org/abs/2407.04620)[test-time-training/ttt-lm-pytorch](https://github.com/test-time-training/ttt-lm-pytorch?tab=readme-ov-file)
* 

#### Multiple instance learning

* TimeMIL: Advancing Multivariate Time Series Classification via a Time-aware Multiple Instance Learning [ICML2024](https://arxiv.org/abs/2405.03140) [xiwenc1/TimeMIL](https://github.com/xiwenc1/TimeMIL)
* 

#### NeXt  (Classic networks make a comeback)

* A ConvNet for the 2020s [CVPR2022](https://arxiv.org/abs/2201.03545) [ConvNext](https://github.com/facebookresearch/ConvNeXt)
* ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders [2 Jan 2023](https://arxiv.org/abs/2301.00808) [ConvNeXt-V2](https://github.com/facebookresearch/ConvNeXt-V2)
* ModernTCN：A Modern Pure Convolution Structure for General Time Series Analysis [ICLR2024](https://openreview.net/forum?id=vpJMJerXHU) [luodhhh/ModernTCN](https://github.com/luodhhh/ModernTCN)
* InceptionNeXt: When Inception Meets ConvNeXt [CVPR2024](https://arxiv.org/abs/2303.16900) [InceptionNeXt](https://github.com/sail-sg/inceptionnext)
* RWKV: Reinventing RNNs for the Transformer Era [22 May 2023](https://arxiv.org/abs/2305.13048)
* RWKV-TS: Beyond Traditional Recurrent Neural Network for Time Series Tasks [arxiv17 Jan 2024](https://arxiv.org/abs/2401.09093) [RWKV-TS](https://github.com/howard-hou/RWKV-TS)
* Efficient and Effective Time-Series Forecasting with Spiking Neural Networks [ICML2024](https://arxiv.org/abs/2402.01533)
* xLSTM: Extended Long Short-Term Memory [7 May 2024](https://arxiv.org/abs/2405.04517) [xLSTM]()
* Unlocking the Power of LSTM for Long Term Time Series Forecasting [19 Aug 2024](https://arxiv.org/abs/2408.10006) 
* TransNeXt: Robust Foveal Visual Perception for Vision Transformers [CVPR2024](https://arxiv.org/abs/2311.17132)

#### Federated learning

* PeFAD: A Parameter-Efficient Federated Framework for Time Series Anomaly Detection [SIGKDD 2024](https://arxiv.org/abs/2406.02318) [PeFAD](https://github.com/xu737/PeFAD)
* Time-FFM: Towards LM-Empowered Federated Foundation Model for Time Series Forecasting [NeurIPS24 ](https://arxiv.org/abs/2405.14252) []()

#### Biosignal dataset

* Neuro-GPT: Developing A Foundation Model for EEG [arxiv 7 Nov 2023](https://arxiv.org/abs/2311.03764)
* Brant: Foundation Model for Intracranial Neural Signal [NeurIPS23](http://yangy.org/works/brainnet/NeurIPS23_Brant.pdf)
* Brant-2: Foundation Model for Brain Signals [15 Feb 2024](https://arxiv.org/abs/2402.10251)
* Brant-X: A Unified Physiological Signal Alignment Framework [KDD2024](http://yangy.org/works/brainnet/KDD24_BrantX.pdf)
* PPi: Pretraining Brain Signal Model for Patient-independent Seizure Detection [NeurIPS23](http://yangy.org/works/brainnet/NeurIPS23_PPi.pdf)
* Large-scale training of foundation models for wearable biosignals [submit ICLR 2024](https://openreview.net/forum?id=pC3WJHf51j)
* BIOT: Cross-data Biosignal Learning in the Wild [NeurIPS23](https://arxiv.org/abs/2305.10351) [BIOT](https://github.com/ycq091044/BIOT)
* Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI [submit ICLR 2024](https://openreview.net/forum?id=QzTpTRVtrP)
* Practical intelligent diagnostic algorithm for wearable 12-lead ECG via self-supervised learning on large-scale dataset [Nature Communications 2023](https://www.nature.com/articles/s41467-023-39472-8)
*  Large AI Models in Health Informatics: Applications, Challenges, and the Future [IEEE Journal of Biomedical and Health Informatics](https://arxiv.org/abs/2303.11568) [Awesome-Healthcare-Foundation-Models](https://github.com/Jianing-Qiu/Awesome-Healthcare-Foundation-Models)
*  Data science opportunities of large language models for neuroscience and biomedicine [Neuron](https://www.sciencedirect.com/science/article/pii/S0896627324000424)
* BioSignal Copilot: Leveraging the power of LLMs in drafting reports
  for biomedical signals [July 06, 2023](https://www.medrxiv.org/content/10.1101/2023.06.28.23291916v1)
* Health-LLM: Large Language Models for Health Prediction via Wearable Sensor Data [12 Jan 2024](https://arxiv.org/abs/2401.06866)
* Self-supervised Learning for Electroencephalogram: A Systematic Survey [9 Jan 2024](https://arxiv.org/abs/2401.05446)
* Learning Topology-Agnostic EEG Representations
  with Geometry-Aware Modeling [NeurIPS 2023](https://papers.nips.cc/paper_files/paper/2023/hash/a8c893712cb7858e49631fb03c941f8d-Abstract-Conference.html) [MMM](https://seqml.github.io/MMM/)
* A Survey of Large Language Models in Medicine: Progress, Application, and Challenge [9 Nov 2023](https://arxiv.org/abs/2311.05112) [AI-in-Health/MedLLMsPracticalGuide](https://github.com/AI-in-Health/MedLLMsPracticalGuide)
* EEG-GPT: Exploring Capabilities of Large Language Models for EEG Classification and Interpretation [31 Jan 2024](https://arxiv.org/abs/2401.18006)
* A Survey on Multimodal Wearable Sensor-based
  Human Action Recognition [14 Apr 2024](https://arxiv.org/abs/2404.15349)
* Unveiling Thoughts: A Review of Advancements in EEG Brain Signal Decoding into Text [26 Apr 2024](https://arxiv.org/abs/2405.00726)
* AI for Biomedicine in the Era of Large Language Models [23 Mar 2024](https://arxiv.org/abs/2403.15673)
* NeuroLM: A Universal Multi-task Foundation Model for Bridging the Gap between Language and EEG Signals [27 Aug 2024](https://arxiv.org/abs/2409.00101)
* EEG-Language Modeling for Pathology Detection [2 Sep 2024](https://arxiv.org/abs/2409.07480)
* Interpretable and Robust AI in EEG Systems: A Survey [21 Apr 2023](https://arxiv.org/abs/2304.10755)
* A Survey of Spatio-Temporal EEG data Analysis: from Models to Applications [26 Sep 2024](https://arxiv.org/abs/2410.08224)
* NeuroLM: A Universal Multi-task Foundation Model for Bridging the Gap between Language and EEG Signals [27 Aug 2024](https://arxiv.org/abs/2409.00101)
* Repurposing Foundation Model for Generalizable Medical Time Series Classification [3 Oct 2024](https://arxiv.org/abs/2410.03794) [FORMED](https://github.com/DL4mHealth/FORMED)
* A Survey of Few-Shot Learning for Biomedical Time Series [3 May 2024](https://arxiv.org/abs/2405.02485)

####  Foundation for other domains

* Foundation Models for *Weather and Climate Data* Understanding: A Comprehensive Survey [5 Dec 2023](https://arxiv.org/abs/2312.03014)
* [Towards Urban General Intelligence: A Review and Outlook of Urban Foundation Models](https://arxiv.org/abs/2402.01749 ) [usail-hkust/Awesome-Urban-Foundation-Models](https://github.com/usail-hkust/Awesome-Urban-Foundation-Models)
* Urban Foundation Models: A Survey [KDD2024](https://www.researchgate.net/profile/Weijia-Zhang-6/publication/382025953_Urban_Foundation_Models_A_Survey/links/6688a92c0a25e27fbc2ba75a/Urban-Foundation-Models-A-Survey.pdf)

#### Multimodal TS

* Biosignal
  * Frozen Language Model Helps ECG Zero-Shot Learning [22 Mar 2023](https://arxiv.org/abs/2303.12311)
  * Learning Transferable Time Series Classifier with Cross-Domain
    Pre-training from Language Model [19 Mar 2024](https://arxiv.org/abs/2403.12372) [CrossTimeNet](https://github.com/Mingyue-Cheng/CrossTimeNet)
  * Zero-Shot ECG Diagnosis with Large Language Models and Retrieval-Augmented Generation [ML4H2023](https://proceedings.mlr.press/v225/yu23b/yu23b.pdf)
  * Large Language Models with Retrieval-Augmented Generation for Zero-Shot Disease Phenotyping [11 Dec 2023](https://arxiv.org/abs/2312.06457)
  * Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement [11 Mar 2024](https://arxiv.org/abs/2403.06659v1)
  * Electrocardiogram Instruction Tuning for Report Generation [7 Mar 2024](https://arxiv.org/abs/2403.04945)
  * Multimodal Pretraining of Medical Time Series and Notes [PMLR2023](https://proceedings.mlr.press/v225/king23a.html) [kingrc15/multimodal-clinical-pretraining](https://github.com/kingrc15/multimodal-clinical-pretraining)
  * SleepFM: Multi-modal Representation Learning for Sleep across ECG, EEG and
    Respiratory Signals [AAAI 2024 Spring Symposium Series Clinical FMs](https://openreview.net/pdf?id=cDXtscWCKC)
  * [[2408.07773\] MedTsLLM: Leveraging LLMs for Multimodal Medical Time Series Analysis (arxiv.org)](https://arxiv.org/abs/2408.07773) [MedTsLLM](https://github.com/flixpar/med-ts-llm)
* Financial
  * FinGPT: Open-Source Financial Large Language Models [arxiv 9 Jun 2023](https://arxiv.org/abs/2306.06031) [AI4Finance-Foundation/FinNLP](https://github.com/AI4Finance-Foundation/FinNLP)
  * FinVis-GPT: A Multimodal Large Language Model for Financial Chart Analysis [ (FinLLM 2023)@IJCAI 2023](https://arxiv.org/abs/2308.01430)
  * Insight Miner: A Time Series Analysis Dataset for Cross-Domain Alignment with Natural Language [NeurIPS2023-AI4Science Poster](https://openreview.net/forum?id=E1khscdUdH
  * A Survey of Large Language Models for Financial Applications: Progress, Prospects and Challenges [15 Jun 2024](https://arxiv.org/abs/2406.11903)
* Other fields
  * GPT4MTS: Prompt-Based Large Language Model for Multimodal Time-Series
    Forecasting [AAAI2024](https://ojs.aaai.org/index.php/AAAI/article/view/30383)
  * Advancing Time Series Classification with Multimodal Language Modeling [19 Mar 2024 ](https://arxiv.org/abs/2403.12371) [Mingyue-Cheng/InstructTime](https://github.com/Mingyue-Cheng/InstructTime)
  * Frequency-Aware Masked Autoencoders for Multimodal Pretraining on Biosignals [12 Sep 2023 ](https://arxiv.org/abs/2309.05927)
  * FOCAL: Contrastive Learning for Multimodal Time-Series Sensing Signals in Factorized Orthogonal Latent Space [*NeurIPS'23* 30 Oct 2023](https://arxiv.org/abs/2310.20071) [focal](https://github.com/tomoyoshki/focal)
  * Multimodal Adaptive Emotion Transformer with Flexible Modality Inputs on A Novel Dataset with Continuous Labels [ACMMM 27 October 2023](https://dl.acm.org/doi/10.1145/3581783.3613797)
  * Improving day-ahead Solar Irradiance Time Series
    Forecasting by Leveraging Spatio-Temporal Context [1 Jun 2023](https://arxiv.org/abs/2306.01112) [CrossViVit](https://github.com/gitbooo/CrossViVit)
  * DualTime: A Dual-Adapter Multimodal Language Model for Time Series Representation [7 Jun 2024](https://arxiv.org/abs/2406.06620)

#### Small && Efficient Language Model

* Mipha: A Comprehensive Overhaul of Multimodal Assistant with Small Language Models [*10 Mar 2024*](https://arxiv.org/abs/2403.06199) [LLaVA-Phi](https://github.com/zhuyiche/llava-phi)
* Efficient Multimodal Large Language Models:A Survey [17 May 2024](https://arxiv.org/abs/2405.10739) [swordlidev/Efficient-Multimodal-LLMs-Survey](https://github.com/swordlidev/Efficient-Multimodal-LLMs-Survey)
* On-Device Language Models: A Comprehensive Review [26 Aug 2024](https://arxiv.org/abs/2409.00088) [NexaAI/Awesome-LLMs-on-device](https://github.com/NexaAI/Awesome-LLMs-on-device)
* Small Language Models: Survey, Measurements, and Insights [24 Sep 2024](https://arxiv.org/abs/2409.15790) [UbiquitousLearning/SLM_Survey](https://github.com/UbiquitousLearning/SLM_Survey)

#### Benchmark && Analysis 

* TS-Benchmark: A Benchmark for Time Series Databases [ICDE2021](https://ieeexplore.ieee.org/abstract/document/9458659)
* TimeEval: a benchmarking toolkit for time series anomaly detection algorithms [VLDB2022](https://dl.acm.org/doi/abs/10.14778/3554821.3554873)
* Class-incremental Learning for Time Series: Benchmark and Evaluation [KDD2024(ADS track)](https://arxiv.org/abs/2402.12035) [zqiao11/TSCIL](https://github.com/zqiao11/TSCIL)
* TFB: Towards Comprehensive and Fair Benchmarking of Time
  Series Forecasting Methods [VLDB2024](https://arxiv.org/abs/2403.20150) [TFB](https://github.com/decisionintelligence/TFB)
* The Capacity and Robustness Trade-off: Revisiting the Channel Independent Strategy for Multivariate Time Series Forecasting [TKDE2024](https://arxiv.org/abs/2304.05206) [channel_independent_MTSF](https://github.com/hanlu-nju/channel_independent_MTSF)
* Deep Time Series Models: A Comprehensive Survey and Benchmark [18 Jul 2024](https://arxiv.org/abs/2407.13278) [TSLib](https://github.com/thuml/Time-Series-Library)
* UP2ME: Univariate Pre-training to Multivariate Fine-tuning as a General-purpose Framework for Multivariate Time Series Analysis [ICML2024](https://openreview.net/pdf?id=aR3uxWlZhX) [UP2ME](https://github.com/Thinklab-SJTU/UP2ME)
* Time-MMD: A New Multi-Domain Multimodal Dataset for Time Series Analysis [12 Jun 2024](https://arxiv.org/abs/2406.08627) [AdityaLab/MM-TSFlib (github.com)](https://github.com/AdityaLab/MM-TSFlib)
* TSI-Bench: Benchmarking Time Series Imputation [18 Jun 2024](https://arxiv.org/abs/2406.12747v1) [TSI-Bench](https://github.com/WenjieDu/AwesomeImputation) 
* Guidelines for Augmentation Selection in Contrastive Learning for Time Series Classification [12 Jul 2024](https://arxiv.org/abs/2407.09336v1) [TS-Contrastive-Augmentation-Recommendation](https://github.com/DL4mHealth/TS-Contrastive-Augmentation-Recommendation)
*  FoundTS: Comprehensive and Unified Benchmarking of Foundation Models for Time Series Forecasting [15 Oct 2024](https://arxiv.org/abs/2410.11802) [FoundTS-C2B0](https://anonymous.4open.science/r/FoundTS-C2B0/README.md)
*  LibEER: A Comprehensive Benchmark and Algorithm Library for EEG-based Emotion Recognition [13 Oct 2024](https://arxiv.org/abs/2410.09767) [LibEER](https://github.com/ButterSen/LibEER)

#### Survey4TS

*  Representation learning(self-supervised learning && Semi-supervised learning&&Supervised learning)

  * Self-supervised Contrastive Representation Learning for Semi-supervised Time-Series Classification [TPAMI 13 Aug 2022](https://arxiv.org/abs/2208.06616) [CA-TCC](https://github.com/emadeldeen24/CA-TCC)
  * Deep Learning for Time Series Classification and Extrinsic Regression: A Current Survey [ACM Computing Surveys, 2023](https://dl.acm.org/doi/abs/10.1145/3649448)
  * Label-efficient Time Series Representation Learning: A Review [13 Feb 2023](https://arxiv.org/abs/2302.06433)
  * Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects [16 Jun 2023](https://arxiv.org/abs/2306.10125) [SSL4TS](https://github.com/qingsongedu/Awesome-SSL4TS) 
  * Unsupervised Representation Learning for Time Series: A Review [3 Aug 2023](https://arxiv.org/abs/2308.01578) [ULTS](https://github.com/mqwfrog/ULTS)
  * Self-Supervised Learning for Time Series: Contrastive or Generative? [AI4TS workshop at IJCAI 2023](https://github.com/AI4TS/AI4TS.github.io/blob/main/CameraReadys%201-22%202/5%5CCameraReady%5CIJCAI23_TSworkshop_Jun29.pdf) [SSL_Comparison](https://github.com/DL4mHealth/SSL_Comparison)
  * Self-Supervised Contrastive Learning for Medical Time Series: A Systematic Review [*Sensors* in 2023](https://www.mdpi.com/1424-8220/23/9/4221) [Contrastive-Learning-in-Medical-Time-Series-Survey](https://github.com/DL4mHealth/Contrastive-Learning-in-Medical-Time-Series-Survey)
  * Applications of Self-Supervised Learning to Biomedical Signals: where are we now [**post date 2023-04-11**](https://www.techrxiv.org/articles/preprint/Applications_of_Self-Supervised_Learning_to_Biomedical_Signals_where_are_we_now/22567021/2)
  * What Constitutes Good Contrastive Learning in Time-Series Forecasting? [last revised 13 Aug 2023](https://arxiv.org/abs/2306.12086)
  * A review of self-supervised learning methods in the field of ECG [2023](http://fcst.ceaj.org/CN/PDF/10.3778/j.issn.1673-9418.2310043?token=84f995acdf3c47919c29ae81ccde6524)
  * Universal Time-Series Representation Learning: A Survey [8 Jan 2024](https://arxiv.org/abs/2401.03717) [itouchz/awesome-deep-time-series-representations](https://github.com/itouchz/awesome-deep-time-series-representations)

  * Deep Learning for Trajectory Data Management and Mining: A Survey and Beyond [21 Mar 2024](https://arxiv.org/abs/2403.14151) [yoshall/Awesome-Trajectory-Computing](https://github.com/yoshall/Awesome-Trajectory-Computing)
  * Scaling-laws for Large Time-series Models [22 May 2024]( https://arxiv.org/abs/2405.13867)
  * Deep Time Series Forecasting Models: A Comprehensive Survey [*Mathematics 2024*](https://www.mdpi.com/2227-7390/12/10/1504)
*  GNN4TS

  * A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection [7 Jul 2023](https://arxiv.org/abs/2307.03759) [KimMeen/Awesome-GNN4TS](https://github.com/KimMeen/Awesome-GNN4TS)
  * K-Link: Knowledge-Link Graph from LLMs for Enhanced Representation Learning in Multivariate Time-Series Data [6 Mar 2024](https://arxiv.org/abs/2403.03645)
*  Generative models
   *  General 
      *  A Survey of Generative Techniques for Spatial-Temporal Data Mining [15 May 2024 ](https://arxiv.org/abs/2405.09592)

   *  Diffusion4TS

      * Diffusion models for time-series applications: a survey [1 May 2023](https://arxiv.org/abs/2305.00624)
      * A Survey on Diffusion Models for Time Series and Spatio-Temporal Data [29 Apr 2024](https://arxiv.org/abs/2404.18886) [yyysjz1997/Awesome-TimeSeries-SpatioTemporal-Diffusion-Model](https://github.com/yyysjz1997/Awesome-TimeSeries-SpatioTemporal-Diffusion-Model)

*  LLM4TS

  * Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook [arxiv 16 Oct 2023](https://arxiv.org/abs/2310.10196) [Awesome-TimeSeries-SpatioTemporal-LM-LLM](https://github.com/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM)
  * Large Language Models for Time Series: A Survey [2 Feb 2024](https://arxiv.org/abs/2402.01801) [xiyuanzh/awesome-llm-time-series](https://github.com/xiyuanzh/awesome-llm-time-series)
  * Position Paper:What Can Large Language Models Tell Us about Time Series Analysis [5 Feb 2024](https://arxiv.org/abs/2402.02713)
  * Empowering Time Series Analysis with Large Language Models: A Survey [5 Feb 2024](https://arxiv.org/abs/2402.03182)
  * Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities [16 Feb 2024](https://arxiv.org/abs/2402.10835)
  * A Survey of Time Series Foundation Models: Generalizing Time Series Representation with Large Language Model [3 May 2024](https://arxiv.org/abs/2405.02358) [start2020/Awesome-TimeSeries-LLM-FM](https://github.com/start2020/Awesome-TimeSeries-LLM-FM)
  * Large Language Models for Mobility in Transportation Systems: A Survey on Forecasting Tasks [3 May 2024](https://arxiv.org/abs/2405.02357) 
  * 
*  Foundation  && Pre-Trained models

  * A Survey on Time-Series Pre-Trained Models [18 May 2023](https://arxiv.org/abs/2305.10716)  [time-series-ptms](https://github.com/qianlima-lab/time-series-ptms)

  * Toward a Foundation Model for Time Series Data [21 Oct 2023](https://dl.acm.org/doi/abs/10.1145/3583780.3615155) [code](https://sites.google.com/view/timeclr)

  * A Review for Pre-Trained Transformer-Based Time Series Forecasting Models  [ITMS2023](https://ieeexplore.ieee.org/abstract/document/10317721)

  * A Survey of Deep Learning and Foundation Models for Time Series Forecasting [25 Jan 2024](https://arxiv.org/abs/2401.13912)
  * Foundation Models for Time Series Analysis: A Tutorial and Survey [21 Mar 2024](https://arxiv.org/abs/2403.14735)
  * Heterogeneous Contrastive Learning for Foundation Models and Beyond [30 Mar 2024](https://arxiv.org/abs/2404.00225)
  * A Comprehensive Survey of Large Language Models and Multimodal Large Language Models in Medicine [14 May 2024](https://arxiv.org/abs/2405.08603)
*  Application

  * Deep Learning for Multivariate Time Series Imputation: A Survey [6 Feb 2024](https://arxiv.org/abs/2402.04059) [WenjieDu/Awesome_Imputation](https://github.com/WenjieDu/Awesome_Imputation)
*  Chinese
   *  任利强,贾舒宜,王海鹏,等.基于深度学习的时间序列分类研究综述[J/OL].电子与信息学报:1-23[2024-05-25].http://kns.cnki.net/kcms/detail/11.4494.TN.20240109.0749.008.html.
   *  毛远宏,孙琛琛,徐鲁豫,等.基于深度学习的时间序列预测方法综述[J].微电子学与计算机,2023,40(04):8-17.DOI:10.19304/J.ISSN1000-7180.2022.0725.
   *  梁宏涛,刘硕,杜军威,等.深度学习应用于时序预测研究综述[J].计算机科学与探索,2023,17(06):1285-1300.


#### Workshop

* [MulTiSA 2024 | MultiTISA 2024](http://multisa2024.org//)  *in conjunction with ICDE'24*
* 

#### Project

* [ddz16/TSFpaper](https://github.com/ddz16/TSFpaper)
* [Time_Series_Instruct](https://github.com/michael-wzhu/Time_Series_Instruct)
* [qingsongedu/Awesome-TimeSeries-AIOps-LM-LLM](https://github.com/qingsongedu/Awesome-TimeSeries-AIOps-LM-LLM)
* [LLM for Time Series](https://github.com/liaoyuhua/LLM4TS)
* [Time Series AI Papers](https://github.com/xiyuanzh/time-series-papers)
* [Multivariate Time Series Transformer Framework](https://github.com/gzerveas/mvts_transformer)
* [xiyuanzh/time-series-papers](https://github.com/xiyuanzh/time-series-papers)
* [vincentlux/Awesome-Multimodal-LLM](https://github.com/vincentlux/Awesome-Multimodal-LLM)
* 
* [yyysjz1997/Awesome-TimeSeries-SpatioTemporal-Diffusion-Model](https://github.com/yyysjz1997/Awesome-TimeSeries-SpatioTemporal-Diffusion-Model)
* [SitaoLuan/LLM4Graph](https://github.com/SitaoLuan/LLM4Graph)
* [willxxy/awesome-mmps](https://github.com/willxxy/awesome-mmps)
* [mintisan/awesome-kan: A comprehensive collection of KAN(Kolmogorov-Arnold Network)-related resources, including libraries, projects, tutorials, papers, and more, for researchers and developers in the Kolmogorov-Arnold Network field. (github.com)](https://github.com/mintisan/awesome-kan)
* [xmindflow/Awesome_Mamba](https://github.com/xmindflow/Awesome_Mamba)
* **Foundation-Models**
  * [uncbiag/Awesome-Foundation-Models](https://github.com/uncbiag/Awesome-Foundation-Models)
  * [UbiquitousLearning/Efficient_Foundation_Model_Survey](https://github.com/ubiquitouslearning/efficient_foundation_model_survey)
  * [zhanghm1995/Forge_VFM4AD](https://github.com/zhanghm1995/Forge_VFM4AD)
  * [Yangyi-Chen/Multimodal-AND-Large-Language-Models](https://github.com/Yangyi-Chen/Multimodal-AND-Large-Language-Models)
  * [MM-LLMs: Recent Advances in MultiModal Large Language Models](https://mm-llms.github.io/)
  * [A Survey on Benchmarks of Multimodal Large
    Language Models]() [swordlidev/Evaluation-Multimodal-LLMs-Survey](swordlidev/Evaluation-Multimodal-LLMs-Survey)
  * [Learning on Multimodal Graphs: A Survey](https://arxiv.org/abs/2402.05322)
  * [The (R)Evolution of Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2402.12451)
  * [A Practical Guide for Medical Large Language Models](https://github.com/AI-in-Health/MedLLMsPracticalGuide)
  * [Instruction Tuning for Large Language Models: A Survey](https://arxiv.org/abs/2308.10792) [xiaoya-li/Instruction-Tuning-Survey](https://github.com/xiaoya-li/Instruction-Tuning-Survey)
  * [Visual Instruction Tuning towards General-Purpose Multimodal Model: A Survey](https://arxiv.org/ abs/2312.16602) 
  * [Brain-Conditional Multimodal Synthesis: A Survey and Taxonomy](https://arxiv.org/pdf/2401.00430.pdf)
  * [Towards Graph Foundation Models: A Survey and Beyond](https://arxiv.org/abs/2310.11829)

#### Self-supervised learning tools

* [Westlake-AI/openmixup: CAIRI Supervised, Semi- and Self-Supervised Visual Representation Learning Toolbox and Benchmark (github.com)](https://github.com/Westlake-AI/openmixup)
* [open-mmlab/mmselfsup: OpenMMLab Self-Supervised Learning Toolbox and Benchmark (github.com)](https://github.com/open-mmlab/mmselfsup)
* [lightly-ai/lightly: A python library for self-supervised learning on images. (github.com)](https://github.com/lightly-ai/lightly)
* 


#### Blog list

* [Anomaly Detection in Time Series using ChatGPT]( https://medium.com/@sztistvan/anomaly-detection-in-time-series-using-chatgpt-3fc48f958c88)
* [Change Point Detection in Time Series using ChatGPT](https://medium.com/@sztistvan/change-point-detection-in-time-series-using-chatgpt-22cc9172a130)
* [Huggingface 镜像站](https://hf-mirror.com/)
* 

* https://mingyue-cheng.github.io/)

#### Laboratory and Researcher Resources

##### Medicine Domain

- **HuiguangHe** - [Chinese Academy of Sciences, Institute of Automation](https://ia.cas.cn/rcdw/yjy/202404/t20240422_7130925.html)
  - **Changde Du** - [Personal Homepage](https://changdedu.github.io/)

- **Bao-Liang Lu** - [Home Page](https://bcmi.sjtu.edu.cn/~blu/)
  - **Wei-Long Zheng** - [Personal Homepage](https://weilongzheng.github.io/)
- **Xun Chen** - [University of Science and Technology of China](http://staff.ustc.edu.cn/~xunchen/)
- **DongruiWu** - [Huazhong University of Science and Technology, Brain-Computer Interface and Machine Learning Lab](http://faculty.hust.edu.cn/drwu/zh_CN/index.htm)
- **Yang Yang** - [Zhejiang University](http://yangy.org/)
- **Shenda Hong** - [Personal Homepage](https://hsd1503.github.io/)
- **Xiang Zhang** [Personal Homepage](https://xiangzhang.info/)

##### General Domain

- **Mingsheng Long** - [Tsinghua University](http://ise.thss.tsinghua.edu.cn/~mlong/)
- **Huaiyu Wan**  [Publications](https://scholar.google.com/citations?hl=zh-CN&user=T5wVWIUAAAAJ)
  - **Shengnan Guo** - [Faculty Directory](http://faculty.bjtu.edu.cn/9685/)
  - **Haomin Wen** - [Personal Homepage](https://wenhaomin.github.io/)
- **MinWu ** - [Google Site](https://sites.google.com/site/wumincf/)
  - **Emadeldeen Eldele** - [Personal Homepage](https://emadeldeen24.github.io/)
  - **Yucheng Wang** - [Personal Homepage](https://frank-wang-oss.github.io/)
- **Ming Jin** - [Home Page](https://mingjin.dev/)
- **Yuxuan Liang** - [Publications](https://yuxuanliang.com/publications/)
- **Xiyuan Zhang** - [Home Page](https://xiyuanzh.github.io/)
- **Mingyue Cheng** - [Home Page](https://mingyue-cheng.github.io/)

##### Lab and Resource

- **Deep Learning for Mobile Health Lab** - [GitHub Repository](https://github.com/DL4mHealth)
- **Temporal and Spatial Data Mining Research Teams** - [Zhihu Discussion](https://www.zhihu.com/question/617528629/answer/3177883285)

### Course

* [Time Series Analysis from nan jing university](https://www.lamda.nju.edu.cn/yehj/TSA2023/) 
* [Time-Series Analysis from intel company ](https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/training/course-time-series-analysis.html)
* [北京大学数学科学学院李东风2024年春季学期课程主页 (pku.edu.cn)](https://www.math.pku.edu.cn/teachers/lidf/course/)

#### Others

* 
