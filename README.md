# AI4TS

Awesome resources focus on the application of cutting-edge AI technologies for time-series analysis (**AI4TS **). They delve into advanced topics such as self-supervised learning (**SSL**), Graph Neural Networks for Time Series (**GNN4TS**), Large Language Models for Time Series (**LLM4TS**), **Diffusion** models, Mixture-of-Experts (**MoE**) architectures and **Mamba** models, Kolmogorov Arnold Networks (**KAN**) among others. These resources span various domains, including healthcare, finance, and traffic, offering a comprehensive view of the field. In addition, they feature top-notch tutorials, courses, and workshops from prestigious conferences, hosted by globally renowned scholars and research teams. Whether you're a professional, data scientist, or researcher, these tools and techniques can significantly enhance your time-series data analysis capabilities, providing a clear roadmap for your studies.

#### LLM4TS

* Forecasting
  * PromptCast: A New Prompt-based Learning Paradigm for Time Series Forecasting [arxiv 20 Sep 2022](https://arxiv.org/abs/2210.08964) [PISA)](https://github.com/HaoUNSW/PISA)
  * Temporal Data Meets LLM -- Explainable Financial Time Series Forecasting [arxiv 19 Jun 2023](https://arxiv.org/abs/2306.11025)
  * Time-LLM: Time Series Forecasting by Reprogramming Large Language Models [arxiv 3 Oct 2023](https://arxiv.org/abs/2310.01728)
  * TimeGPT-1 [arxiv 2023 *5 Oct 2023*](https://arxiv.org/abs/2310.03589)
  * TEMPO: Prompt-based Generative Pre-trained Transformer for Time Series Forecasting [ arxiv 8 Oct 2023](https://arxiv.org/abs/2310.04948) 
  * Pushing the Limits of Pre-training for Time Series Forecasting in the CloudOps Domain [arxiv 2023 8 Oct 2023](https://arxiv.org/abs/2310.05063)
  * Large Language Models Are Zero-Shot Time Series Forecasters [ NeurIPS 2023 11 Oct 2023](https://arxiv.org/abs/2310.07820)  [llmtime](https://github.com/ngruver/llmtime)
  * Lag-Llama: Towards Foundation Models for Time Series Forecasting [arxiv 12 Oct 2023](https://arxiv.org/abs/2310.08278)  [Lag-Llama](https://github.com/kashif/pytorch-transformer-ts)
  * iTransformer: Inverted Transformers Are Effective for Time Series Forecasting [arxiv 13  Oct 2023 ]() [iTransformer]([GitHub - thuml/iTransformer: This is the official implementation for "iTransformer: Inverted Transformers Are Effective for Time Series Forecasting".](https://github.com/thuml/iTransformer))
  * Harnessing LLMs for Temporal Data - A Study on Explainable Financial Time Series Forecasting [2023.emnlp-industry](https://aclanthology.org/2023.emnlp-industry.69.pdf)
  * LLM4TS: Two-Stage Fine-Tuning for Time-Series Forecasting with Pre-Trained LLMs [arxiv16 Aug 2023](https://arxiv.org/abs/2308.08469) 
  * UniTime: A Language-Empowered Unified Model for Cross-Domain Time Series Forecasting [15 Oct 2023](https://arxiv.org/abs/2310.09751)
  * AutoTimes: Autoregressive Time Series Forecasters via Large Language Models [4 Feb 2024](https://arxiv.org/abs/2402.02370)
  * Unified Training of Universal Time Series Forecasting Transformers [4 Feb 2024](https://arxiv.org/abs/2402.02592) [SalesforceAIResearch/uni2ts](https://github.com/SalesforceAIResearch/uni2ts)
  * LSTPrompt: Large Language Models as Zero-Shot Time Series Forecasters by Long-Short-Term Prompting [25 Feb 2024](https://arxiv.org/abs/2402.16132v1) [LSTPrompt](https://github.com/AdityaLab/lstprompt)
  * Multi-Patch Prediction: Adapting LLMs for Time Series Representation Learning [7 Feb 2024](https://arxiv.org/abs/2402.04852)
  * Chronos: Learning the Language of Time Series [12 Mar 2024](https://arxiv.org/abs/2403.07815) [chronos](https://github.com/amazon-science/chronos-forecasting)
  * S^2 IP-LLM: Semantic Space Informed Prompt Learning with LLM for Time Series Forecasting [9 Mar 2024](https://arxiv.org/abs/2403.05798)
  * CALF: Aligning LLMs for Time Series Forecasting via Cross-modal Fine-Tuning [12 Mar 2024](https://arxiv.org/abs/2403.07300) [CALF](https://github.com/Hank0626/CALF)
* Anomaly Detection
  * Large Language Model Guided Knowledge Distillation for Time Series Anomaly Detection [26 Jan 2024](https://arxiv.org/abs/2401.15123) [AnomalyLLM](https://github.com/fly-orange/AnomalyLLM/tree/main)
  * Large Language Models for Forecasting and Anomaly Detection: A Systematic Literature Review [15 Feb 2024](https://arxiv.org/abs/2402.10350)
  * Large language models can be zero-shot anomaly detectors for time series?  [*23 May 2024*](https://arxiv.org/abs/2405.14755)
  * 
* Imputation 
  * GATGPT: A Pre-trained Large Language Model with Graph Attention Network for Spatiotemporal Imputation [24 Nov 2023](https://arxiv.org/abs/2311.14332)
* Spatio-temporal prediction
  * Spatio-Temporal Graph Learning with Large Language Model [20 Sept 2023](https://openreview.net/forum?id=QUkcfqa6GX)
  * How Can Large Language Models Understand Spatial-Temporal Data? [25 Jan 2024](https://arxiv.org/abs/2401.14192)
  * UrbanGPT: Spatio-Temporal Large Language Models [25 Feb 2024](https://arxiv.org/abs/2403.00813)
  * TPLLM: A Traffic Prediction Framework Based on Pretrained Large Language Models [ 4 Mar 2024](https://arxiv.org/abs/2403.02221v1)
  * Spatial-Temporal Large Language Model for Traffic Prediction [18 Jan 2024](https://arxiv.org/abs/2401.10134)
* One Fits all
  * One Fits All:Power General Time Series Analysis by Pretrained LM [arxiv 23 Feb 2023](https://arxiv.org/abs/2302.11939) [NeurIPS2023-One-Fits-All](https://github.com/DAMO-DI-ML/NeurIPS2023-One-Fits-All) [no-officail reproduction](https://github.com/liaoyuhua/GPT-TS)
  * TEST: Text Prototype Aligned Embedding to Activate LLM's Ability for Time Series [arxiv16 Aug 2023](https://arxiv.org/abs/2308.08241#:~:text=TEST%3A%20Text%20Prototype%20Aligned%20Embedding%20to%20Activate%20LLM's%20Ability%20for%20Time%20Series,-Chenxi%20Sun%2C%20Yaliang&text=This%20work%20summarizes%20two%20strategies,LLM%20to%20handle%20TS%20data.) [TEST](https://github.com/SCXsunchenxi/TEST)
  * Timer: Transformers for Time Series Analysis at Scale [4 Feb 2024](https://arxiv.org/abs/2402.02368)
  * UniTS: Building a Unified Time Series Model  [29 Feb 2024](https://arxiv.org/abs/2403.00131v1) [UniTS](https://github.com/mims-harvard/UniTS)
  * MOMENT: A Family of Open Time-series Foundation Models [6 Feb 2024](https://arxiv.org/abs/2402.03885) [MOMENT](https://anonymous.4open.science/r/BETT-773F/README.md)
  * TSLANet: Rethinking Transformers for Time Series Representation Learning [ICML2024](https://arxiv.org/abs/2404.08472) [TSLANet](https://github.com/emadeldeen24/TSLANet)
  * RWKV-TS: Beyond Traditional Recurrent Neural Network for Time Series Tasks [17 Jan 2024](https://arxiv.org/abs/2401.09093) [RWKV-TS](https://github.com/howard-hou/RWKV-TS)
  * UniCL: A Universal Contrastive Learning Framework for Large Time Series Models [17 May 2024](https://arxiv.org/abs/2405.10597)
  * 


#### Multimodal large models include TS

* Meta-Transformer: A Unified Framework for Multimodal Learning [20 Jul 2023](https://arxiv.org/abs/2307.10802) [Meta-Transformer](https://kxgong.github.io/meta_transformer/)
* UniRepLKNet: A Universal Perception Large-Kernel ConvNet for Audio, Video,Point Cloud, Time-Series and Image Recognition [27 Nov 2023](https://arxiv.org/abs/2311.15599) [UniRepLKNet](https://invictus717.github.io/UniRepLKNet/)
* ViT-Lens-2: Gateway to Omni-modal Intelligence [27 Nov 2023](https://arxiv.org/abs/2311.16081) [ViT-Lens-2](https://github.com/TencentARC/ViT-Lens)

#### Patch && Tokenizers methods

* Patches Are All You Need? [*ICLR 24 Jan 2022*](https://arxiv.org/abs/2201.09792)  [convmixer](https://github.com/locuslab/convmixer)
* A Time Series is Worth 64 Words: Long-term Forecasting with Transformers [ICLR 2023 *27 Nov 2022*](https://arxiv.org/abs/2211.14730) [PatchTST](https://github.com/yuqinie98/PatchTST)
* PatchMixer: A Patch-Mixing Architecture for Long-Term Time Series Forecasting [arxiv  *1 Oct 2023*](https://arxiv.org/abs/2310.00655) [PatchMixer](https://github.com/Zeying-Gong/PatchMixer) [Chinese blog](https://mp.weixin.qq.com/s/gfAqL7bosdc0mxz8SziBbQ)
* Learning to Embed Time Series Patches Independently [NeurIPS Workshop on Self-Supervised Learning: Theory and Practice, 2023](https://arxiv.org/abs/2312.16427) [pits](https://github.com/seunghan96/pits)
* The first step is the hardest: Pitfalls of Representing and Tokenizing Temporal Data for Large Language Models [arxiv 12 Sep 2023](https://arxiv.org/abs/2309.06236)
* What Makes for Good Visual Tokenizers for Large Language Models? [20 May 2023](https://arxiv.org/abs/2305.12223) [GVT](https://github.com/TencentARC/GVT)
* SpeechTokenizer: Unified Speech Tokenizer for Speech Large Language Models [ICLR2024](https://arxiv.org/abs/2308.16692) [SpeechTokenizer](https://0nutation.github.io/SpeechTokenizer.github.io/)
* Pathformer: Multi-scale Transformers with Adaptive Pathways for Time Series Forecasting [ICLR2024](https://github.com/decisionintelligence/pathformer)

#### GNN

* Graph-Aware Contrasting for Multivariate Time-Series Classification [AAAI2024](https://ojs.aaai.org/index.php/AAAI/article/view/29501) [TSGAC](https://github.com/Frank-Wang-oss/TS-GAC)

#### MLPer

* TSMixer: Lightweight MLP-Mixer Model for Multivariate Time Series Forecasting [KDD2023](https://arxiv.org/abs/2306.09364)[PatchTSMixer](https://github.com/IBM/tsfm/blob/main/notebooks/hfdemo/patch_tsmixer_getting_started.ipynb)
* A Multi-Scale Decomposition MLP-Mixer for Time Series Analysis [VLDB2024](https://arxiv.org/abs/2310.11959) [zshhans/MSD-Mixer](https://github.com/zshhans/MSD-Mixer)
* Tiny Time Mixers (TTMs): Fast Pre-trained Models for Enhanced Zero/Few-Shot
  Forecasting of Multivariate Time Series [8 Jan 2024](https://arxiv.org/abs/2401.03955)
* U-Mixer: An Unet-Mixer Architecture with Stationarity Correction for Time Series Forecasting [AAAI2024](https://arxiv.org/abs/2401.02236) [U-Mixer](https://github.com/XiangMa-Shaun/U-Mixer)
* LightTS: Lightweight Time Series Classification with Adaptive
  Ensemble Distillation—Extended Version [SIGMOD 2023](https://arxiv.org/abs/2302.12721) 
* An Analysis of Linear Time Series Forecasting Models [ICML2024](https://arxiv.org/abs//2403.14587)

#### Mixture-of-Experts (MoE)

* Mixture-of-Linear-Experts for Long-term Time Series Forecasting [11 Dec 2023](https://arxiv.org/abs/2312.06786)
* Prompt-based Domain Discrimination for Multi-source Time Series Domain Adaptation [19 Dec 2023](https://arxiv.org/abs/2312.12276)
* A Review of Sparse Expert Models in Deep Learning [4 Sep 2022](https://arxiv.org/abs/2209.01667)
* MoE-Mamba: Efficient Selective State Space Models with Mixture of Experts [8 Jan 2024](https://arxiv.org/abs/2401.04081) [](https://github.com/llm-random/llm-random)
* ST-MoE: Spatio-Temporal Mixture of Experts for Multivariate Time Series Forecasting [2023ISKE](https://ieeexplore.ieee.org/abstract/document/10480934)
* [Tutorial for Mixture of Expert (MoE) Forecasting Model — Merlion 1.1.0 documentation (salesforce.com)](https://opensource.salesforce.com/Merlion/v1.1.0/examples/advanced/2_MoE_Forecasting_tutorial.html)

#### Mamba

* Is Mamba Effective for Time Series Forecasting? [17 Mar 2024](https://arxiv.org/abs/2403.11144) [wzhwzhwzh0921/S-D-Mamba](https://github.com/wzhwzhwzh0921/S-D-Mamba)
* TimeMachine: A Time Series is Worth 4 Mambas for Long-term Forecasting [14 Mar 2024](https://arxiv.org/abs/2403.09898) [Atik-Ahamed/TimeMachine](https://github.com/Atik-Ahamed/TimeMachine)
* STG-Mamba: Spatial-Temporal Graph Learning via Selective State Space Model [19 Mar 2024](https://arxiv.org/abs/2403.12418)
* SiMBA: Simplified Mamba-Based Architecture for Vision and Multivariate Time series [22 Mar 2024](https://arxiv.org/abs/2403.15360) [badripatro/simba](https://github.com/badripatro/Simba)
* MambaMixer: Efficient Selective State Space Models with Dual Token and Channel Selection [29 Mar 2024](https://arxiv.org/abs/2403.19888)
* Traj-LLM: A New Exploration for Empowering Trajectory Prediction with Pre-trained Large Language Models [8 May 2024](https://arxiv.org/abs/2405.04909)

#### KAN

* KAN: Kolmogorov-Arnold Networks [30 Apr 2024](https://arxiv.org/abs/2404.19756) [pykan](https://github.com/KindXiaoming/pykan)
* TKAN: Temporal Kolmogorov-Arnold Networks [arxiv12 May 2024](https://arxiv.org/abs/2405.07344) [TKAN](https://github.com/remigenet/TKAN)
* Kolmogorov-Arnold Networks (KANs) for Time Series Analysis [14 May 2024](https://arxiv.org/abs/2405.08790)
* Feature-Based Time Series Classification with Kolmogorov–Arnold Networks [Simple-KAN-4-Time-Series](https://github.com/MSD-IRIMAS/Simple-KAN-4-Time-Series)

#### Multiple instance learning

* TimeMIL: Advancing Multivariate Time Series Classification via a Time-aware Multiple Instance Learning [ICML2024](https://arxiv.org/abs/2405.03140) [xiwenc1/TimeMIL](https://github.com/xiwenc1/TimeMIL)
* 

#### NeXt  (Classic networks make a comeback)

* A ConvNet for the 2020s [CVPR2022](https://arxiv.org/abs/2201.03545) [ConvNext](https://github.com/facebookresearch/ConvNeXt)
* ConvNeXt V2: Co-designing and Scaling ConvNets with Masked Autoencoders [2 Jan 2023](https://arxiv.org/abs/2301.00808) [ConvNeXt-V2](https://github.com/facebookresearch/ConvNeXt-V2)
* ModernTCN：A Modern Pure Convolution Structure for General Time Series Analysis [ICLR2024](https://openreview.net/forum?id=vpJMJerXHU) [luodhhh/ModernTCN](https://github.com/luodhhh/ModernTCN)
* InceptionNeXt: When Inception Meets ConvNeXt [CVPR2024](https://arxiv.org/abs/2303.16900) [InceptionNeXt](https://github.com/sail-sg/inceptionnext)
* RWKV: Reinventing RNNs for the Transformer Era [22 May 2023](https://arxiv.org/abs/2305.13048)
* RWKV-TS: Beyond Traditional Recurrent Neural Network for Time Series Tasks [arxiv17 Jan 2024](https://arxiv.org/abs/2401.09093) [RWKV-TS](https://github.com/howard-hou/RWKV-TS)
* Efficient and Effective Time-Series Forecasting with Spiking Neural Networks [ICML2024](https://arxiv.org/abs/2402.01533)
* xLSTM: Extended Long Short-Term Memory [7 May 2024](https://arxiv.org/abs/2405.04517) [xLSTM]()

#### Biosignal dataset

* Neuro-GPT: Developing A Foundation Model for EEG [arxiv 7 Nov 2023](https://arxiv.org/abs/2311.03764)
* Brant: Foundation Model for Intracranial Neural Signal [NeurIPS23](http://yangy.org/works/brainnet/NeurIPS23_Brant.pdf)
* PPi: Pretraining Brain Signal Model for Patient-independent Seizure Detection [NeurIPS23](http://yangy.org/works/brainnet/NeurIPS23_PPi.pdf)
* Large-scale training of foundation models for wearable biosignals [submit ICLR 2024](https://openreview.net/forum?id=pC3WJHf51j)
* BIOT: Cross-data Biosignal Learning in the Wild [NeurIPS23](https://arxiv.org/abs/2305.10351) [BIOT](https://github.com/ycq091044/BIOT)
* Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI [submit ICLR 2024](https://openreview.net/forum?id=QzTpTRVtrP)
* Practical intelligent diagnostic algorithm for wearable 12-lead ECG via self-supervised learning on large-scale dataset [Nature Communications 2023](https://www.nature.com/articles/s41467-023-39472-8)
*  Large AI Models in Health Informatics: Applications, Challenges, and the Future [IEEE Journal of Biomedical and Health Informatics](https://arxiv.org/abs/2303.11568) [Awesome-Healthcare-Foundation-Models](https://github.com/Jianing-Qiu/Awesome-Healthcare-Foundation-Models)
*  Data science opportunities of large language models for neuroscience and biomedicine [Neuron](https://www.sciencedirect.com/science/article/pii/S0896627324000424)
* BioSignal Copilot: Leveraging the power of LLMs in drafting reports
  for biomedical signals [July 06, 2023](https://www.medrxiv.org/content/10.1101/2023.06.28.23291916v1)
* Health-LLM: Large Language Models for Health Prediction via Wearable Sensor Data [12 Jan 2024](https://arxiv.org/abs/2401.06866)
* Self-supervised Learning for Electroencephalogram: A Systematic Survey [9 Jan 2024](https://arxiv.org/abs/2401.05446)
* Learning Topology-Agnostic EEG Representations
  with Geometry-Aware Modeling [NeurIPS 2023](https://papers.nips.cc/paper_files/paper/2023/hash/a8c893712cb7858e49631fb03c941f8d-Abstract-Conference.html) [MMM](https://seqml.github.io/MMM/)
* A Survey of Large Language Models in Medicine: Progress, Application, and Challenge [9 Nov 2023](https://arxiv.org/abs/2311.05112) [AI-in-Health/MedLLMsPracticalGuide](https://github.com/AI-in-Health/MedLLMsPracticalGuide)

####  Foundation for other domains

* Foundation Models for *Weather and Climate Data* Understanding: A Comprehensive Survey [5 Dec 2023](https://arxiv.org/abs/2312.03014)
* [Towards Urban General Intelligence: A Review and Outlook of Urban Foundation Models](https://arxiv.org/abs/2402.01749 ) [usail-hkust/Awesome-Urban-Foundation-Models](https://github.com/usail-hkust/Awesome-Urban-Foundation-Models)
* 

#### Multimodal TS

* Biosignal
  * Frozen Language Model Helps ECG Zero-Shot Learning [22 Mar 2023](https://arxiv.org/abs/2303.12311)
  * Learning Transferable Time Series Classifier with Cross-Domain
    Pre-training from Language Model [19 Mar 2024](https://arxiv.org/abs/2403.12372) [CrossTimeNet](https://github.com/Mingyue-Cheng/CrossTimeNet)
  * Zero-Shot ECG Diagnosis with Large Language Models and Retrieval-Augmented Generation [ML4H2023](https://proceedings.mlr.press/v225/yu23b/yu23b.pdf)
  * Large Language Models with Retrieval-Augmented Generation for Zero-Shot Disease Phenotyping [11 Dec 2023](https://arxiv.org/abs/2312.06457)
  * Zero-Shot ECG Classification with Multimodal Learning and Test-time Clinical Knowledge Enhancement [11 Mar 2024](https://arxiv.org/abs/2403.06659v1)
  * Electrocardiogram Instruction Tuning for Report Generation [7 Mar 2024](https://arxiv.org/abs/2403.04945)
  * Multimodal Pretraining of Medical Time Series and Notes [PMLR2023](https://proceedings.mlr.press/v225/king23a.html) [kingrc15/multimodal-clinical-pretraining](https://github.com/kingrc15/multimodal-clinical-pretraining)
  * SleepFM: Multi-modal Representation Learning for Sleep across ECG, EEG and
    Respiratory Signals [AAAI 2024 Spring Symposium Series Clinical FMs](https://openreview.net/pdf?id=cDXtscWCKC)
* Financial
  * FinGPT: Open-Source Financial Large Language Models [arxiv 9 Jun 2023](https://arxiv.org/abs/2306.06031) [AI4Finance-Foundation/FinNLP](https://github.com/AI4Finance-Foundation/FinNLP)
  * FinVis-GPT: A Multimodal Large Language Model for Financial Chart Analysis [ (FinLLM 2023)@IJCAI 2023](https://arxiv.org/abs/2308.01430)
  * Insight Miner: A Time Series Analysis Dataset for Cross-Domain Alignment with Natural Language [NeurIPS2023-AI4Science Poster](https://openreview.net/forum?id=E1khscdUdH
* Other fields
  * GPT4MTS: Prompt-Based Large Language Model for Multimodal Time-Series
    Forecasting [AAAI2024](https://ojs.aaai.org/index.php/AAAI/article/view/30383)
  * Advancing Time Series Classification with Multimodal Language Modeling [19 Mar 2024 ](https://arxiv.org/abs/2403.12371) [Mingyue-Cheng/InstructTime](https://github.com/Mingyue-Cheng/InstructTime)
  * Frequency-Aware Masked Autoencoders for Multimodal Pretraining on Biosignals [12 Sep 2023 ](https://arxiv.org/abs/2309.05927)
  * FOCAL: Contrastive Learning for Multimodal Time-Series Sensing Signals in Factorized Orthogonal Latent Space [*NeurIPS'23* 30 Oct 2023](https://arxiv.org/abs/2310.20071) [focal](https://github.com/tomoyoshki/focal)
  * Multimodal Adaptive Emotion Transformer with Flexible Modality Inputs on A Novel Dataset with Continuous Labels [ACMMM 27 October 2023](https://dl.acm.org/doi/10.1145/3581783.3613797)
  * Improving day-ahead Solar Irradiance Time Series
    Forecasting by Leveraging Spatio-Temporal Context [1 Jun 2023](https://arxiv.org/abs/2306.01112) [CrossViVit](https://github.com/gitbooo/CrossViVit)

#### Survey4TS

*  Representation learning(self-supervised learning && Semi-supervised learning&&Supervised learning)

  * Self-supervised Contrastive Representation Learning for Semi-supervised Time-Series Classification [TPAMI 13 Aug 2022](https://arxiv.org/abs/2208.06616) [CA-TCC](https://github.com/emadeldeen24/CA-TCC)
  * Deep Learning for Time Series Classification and Extrinsic Regression: A Current Survey [ACM Computing Surveys, 2023](https://dl.acm.org/doi/abs/10.1145/3649448)
  * Label-efficient Time Series Representation Learning: A Review [13 Feb 2023](https://arxiv.org/abs/2302.06433)
  * Self-Supervised Learning for Time Series Analysis: Taxonomy, Progress, and Prospects [16 Jun 2023](https://arxiv.org/abs/2306.10125) [SSL4TS](https://github.com/qingsongedu/Awesome-SSL4TS) 
  * Unsupervised Representation Learning for Time Series: A Review [3 Aug 2023](https://arxiv.org/abs/2308.01578) [ULTS](https://github.com/mqwfrog/ULTS)
  * Self-Supervised Learning for Time Series: Contrastive or Generative? [AI4TS workshop at IJCAI 2023](https://github.com/AI4TS/AI4TS.github.io/blob/main/CameraReadys%201-22%202/5%5CCameraReady%5CIJCAI23_TSworkshop_Jun29.pdf) [SSL_Comparison](https://github.com/DL4mHealth/SSL_Comparison)
  * Self-Supervised Contrastive Learning for Medical Time Series: A Systematic Review [*Sensors* in 2023](https://www.mdpi.com/1424-8220/23/9/4221) [Contrastive-Learning-in-Medical-Time-Series-Survey](https://github.com/DL4mHealth/Contrastive-Learning-in-Medical-Time-Series-Survey)
  * Applications of Self-Supervised Learning to Biomedical Signals: where are we now [**post date 2023-04-11**](https://www.techrxiv.org/articles/preprint/Applications_of_Self-Supervised_Learning_to_Biomedical_Signals_where_are_we_now/22567021/2)
  * What Constitutes Good Contrastive Learning in Time-Series Forecasting? [last revised 13 Aug 2023](https://arxiv.org/abs/2306.12086)
  * A review of self-supervised learning methods in the field of ECG [2023](http://fcst.ceaj.org/CN/PDF/10.3778/j.issn.1673-9418.2310043?token=84f995acdf3c47919c29ae81ccde6524)
  * Universal Time-Series Representation Learning: A Survey [8 Jan 2024](https://arxiv.org/abs/2401.03717) [itouchz/awesome-deep-time-series-representations](https://github.com/itouchz/awesome-deep-time-series-representations)

  * Deep Learning for Trajectory Data Management and Mining: A Survey and Beyond [21 Mar 2024](https://arxiv.org/abs/2403.14151) [yoshall/Awesome-Trajectory-Computing](https://github.com/yoshall/Awesome-Trajectory-Computing)
  * 

*  GNN4TS

  * A Survey on Graph Neural Networks for Time Series: Forecasting, Classification, Imputation, and Anomaly Detection [7 Jul 2023](https://arxiv.org/abs/2307.03759) [KimMeen/Awesome-GNN4TS](https://github.com/KimMeen/Awesome-GNN4TS)

*  Diffusion4TS

  * Diffusion models for time-series applications: a survey [1 May 2023](https://arxiv.org/abs/2305.00624)
  * A Survey on Diffusion Models for Time Series and Spatio-Temporal Data [29 Apr 2024](https://arxiv.org/abs/2404.18886) [yyysjz1997/Awesome-TimeSeries-SpatioTemporal-Diffusion-Model](https://github.com/yyysjz1997/Awesome-TimeSeries-SpatioTemporal-Diffusion-Model)

*  LLM4TS

  * Large Models for Time Series and Spatio-Temporal Data: A Survey and Outlook [arxiv 16 Oct 2023](https://arxiv.org/abs/2310.10196) [Awesome-TimeSeries-SpatioTemporal-LM-LLM](https://github.com/qingsongedu/Awesome-TimeSeries-SpatioTemporal-LM-LLM)
  * Large Language Models for Time Series: A Survey [2 Feb 2024](https://arxiv.org/abs/2402.01801) [xiyuanzh/awesome-llm-time-series](https://github.com/xiyuanzh/awesome-llm-time-series)
  * Position Paper:What Can Large Language Models Tell Us about Time Series Analysis [5 Feb 2024](https://arxiv.org/abs/2402.02713)
  * Empowering Time Series Analysis with Large Language Models: A Survey [5 Feb 2024](https://arxiv.org/abs/2402.03182)
  * Time Series Forecasting with LLMs: Understanding and Enhancing Model Capabilities [16 Feb 2024](https://arxiv.org/abs/2402.10835)
  * A Survey of Time Series Foundation Models: Generalizing Time Series Representation with Large Language Model [3 May 2024](https://arxiv.org/abs/2405.02358) [start2020/Awesome-TimeSeries-LLM-FM](https://github.com/start2020/Awesome-TimeSeries-LLM-FM)
  * Large Language Models for Mobility in Transportation Systems: A Survey on Forecasting Tasks [3 May 2024](https://arxiv.org/abs/2405.02357) 
  * 

*  Foundation  && Pre-Trained models

  * A Survey on Time-Series Pre-Trained Models [18 May 2023](https://arxiv.org/abs/2305.10716)  [time-series-ptms](https://github.com/qianlima-lab/time-series-ptms)

  * Toward a Foundation Model for Time Series Data [21 Oct 2023](https://dl.acm.org/doi/abs/10.1145/3583780.3615155) [code](https://sites.google.com/view/timeclr)

  * A Review for Pre-Trained Transformer-Based Time Series Forecasting Models  [ITMS2023](https://ieeexplore.ieee.org/abstract/document/10317721)

  * A Survey of Deep Learning and Foundation Models for Time Series Forecasting [25 Jan 2024](https://arxiv.org/abs/2401.13912)
  * Foundation Models for Time Series Analysis: A Tutorial and Survey [21 Mar 2024](https://arxiv.org/abs/2403.14735)
  * Heterogeneous Contrastive Learning for Foundation Models and Beyond [30 Mar 2024](https://arxiv.org/abs/2404.00225)

*  Application

  * Deep Learning for Multivariate Time Series Imputation: A Survey [6 Feb 2024](https://arxiv.org/abs/2402.04059) [WenjieDu/Awesome_Imputation](https://github.com/WenjieDu/Awesome_Imputation)
*  Chinese
   *  任利强,贾舒宜,王海鹏,等.基于深度学习的时间序列分类研究综述[J/OL].电子与信息学报:1-23[2024-05-25].http://kns.cnki.net/kcms/detail/11.4494.TN.20240109.0749.008.html.
   *  毛远宏,孙琛琛,徐鲁豫,等.基于深度学习的时间序列预测方法综述[J].微电子学与计算机,2023,40(04):8-17.DOI:10.19304/J.ISSN1000-7180.2022.0725.
   *  梁宏涛,刘硕,杜军威,等.深度学习应用于时序预测研究综述[J].计算机科学与探索,2023,17(06):1285-1300.


#### Workshop

* [MulTiSA 2024 | MultiTISA 2024](http://multisa2024.org//)  *in conjunction with ICDE'24*
* 

#### Project

* [ddz16/TSFpaper](https://github.com/ddz16/TSFpaper)
* [Time_Series_Instruct](https://github.com/michael-wzhu/Time_Series_Instruct)
* [qingsongedu/Awesome-TimeSeries-AIOps-LM-LLM](https://github.com/qingsongedu/Awesome-TimeSeries-AIOps-LM-LLM)
* [LLM for Time Series](https://github.com/liaoyuhua/LLM4TS)
* [Time Series AI Papers](https://github.com/xiyuanzh/time-series-papers)
* [Multivariate Time Series Transformer Framework](https://github.com/gzerveas/mvts_transformer)
* [xiyuanzh/time-series-papers](https://github.com/xiyuanzh/time-series-papers)
* [vincentlux/Awesome-Multimodal-LLM](https://github.com/vincentlux/Awesome-Multimodal-LLM)
* [yyysjz1997/Awesome-TimeSeries-SpatioTemporal-Diffusion-Model](https://github.com/yyysjz1997/Awesome-TimeSeries-SpatioTemporal-Diffusion-Model)
* [SitaoLuan/LLM4Graph](https://github.com/SitaoLuan/LLM4Graph)
* [willxxy/awesome-mmps](https://github.com/willxxy/awesome-mmps)
* [mintisan/awesome-kan: A comprehensive collection of KAN(Kolmogorov-Arnold Network)-related resources, including libraries, projects, tutorials, papers, and more, for researchers and developers in the Kolmogorov-Arnold Network field. (github.com)](https://github.com/mintisan/awesome-kan)
* **Foundation-Models**
  * [uncbiag/Awesome-Foundation-Models](https://github.com/uncbiag/Awesome-Foundation-Models)
  * [UbiquitousLearning/Efficient_Foundation_Model_Survey](https://github.com/ubiquitouslearning/efficient_foundation_model_survey)
  * [zhanghm1995/Forge_VFM4AD](https://github.com/zhanghm1995/Forge_VFM4AD)
  * [Yangyi-Chen/Multimodal-AND-Large-Language-Models](https://github.com/Yangyi-Chen/Multimodal-AND-Large-Language-Models)
  * [MM-LLMs: Recent Advances in MultiModal Large Language Models](https://mm-llms.github.io/)
  * [Learning on Multimodal Graphs: A Survey](https://arxiv.org/abs/2402.05322)
  * [The (R)Evolution of Multimodal Large Language Models: A Survey](https://arxiv.org/abs/2402.12451)
  * [A Practical Guide for Medical Large Language Models](https://github.com/AI-in-Health/MedLLMsPracticalGuide)
  * [Instruction Tuning for Large Language Models: A Survey](https://arxiv.org/abs/2308.10792) [xiaoya-li/Instruction-Tuning-Survey](https://github.com/xiaoya-li/Instruction-Tuning-Survey)
  * [Visual Instruction Tuning towards General-Purpose Multimodal Model: A Survey](https://arxiv.org/ abs/2312.16602) 
  * [Brain-Conditional Multimodal Synthesis: A Survey and Taxonomy](https://arxiv.org/pdf/2401.00430.pdf)

#### Self-supervised learning tools

* [Westlake-AI/openmixup: CAIRI Supervised, Semi- and Self-Supervised Visual Representation Learning Toolbox and Benchmark (github.com)](https://github.com/Westlake-AI/openmixup)
* [open-mmlab/mmselfsup: OpenMMLab Self-Supervised Learning Toolbox and Benchmark (github.com)](https://github.com/open-mmlab/mmselfsup)
* [lightly-ai/lightly: A python library for self-supervised learning on images. (github.com)](https://github.com/lightly-ai/lightly)
* 


#### Blog list

* [Anomaly Detection in Time Series using ChatGPT]( https://medium.com/@sztistvan/anomaly-detection-in-time-series-using-chatgpt-3fc48f958c88)
* [Change Point Detection in Time Series using ChatGPT](https://medium.com/@sztistvan/change-point-detection-in-time-series-using-chatgpt-22cc9172a130)
* [Huggingface 镜像站](https://hf-mirror.com/)
* 

#### Laboratory

* [Deep Learning for Mobile Health Lab](https://github.com/DL4mHealth)
* [Mingsheng Long - Tsinghua University](http://ise.thss.tsinghua.edu.cn/~mlong/)
* [Yang Yang - Zhejiang University](http://yangy.org/)
* https://yuxuanliang.com/publications/
* [北京交通大学教师名录 (bjtu.edu.cn)](http://faculty.bjtu.edu.cn/9685/)
* [国内外高校和企业里时空数据挖掘相关的团队有哪些？ - 知乎 (zhihu.com)](https://www.zhihu.com/question/617528629/answer/3177883285)
* [Xiyuan Zhang | Home](https://xiyuanzh.github.io/)
* [Mingyue Cheng's HomePage (mingyue-cheng.github.io)](https://mingyue-cheng.github.io/)
* 

### Course

* [Time Series Analysis from nan jing university](https://www.lamda.nju.edu.cn/yehj/TSA2023/) 
* [Time-Series Analysis from intel company ](https://www.intel.com/content/www/us/en/developer/topic-technology/artificial-intelligence/training/course-time-series-analysis.html)
* [北京大学数学科学学院李东风2024年春季学期课程主页 (pku.edu.cn)](https://www.math.pku.edu.cn/teachers/lidf/course/)

#### Others

* 
